
1) Allouer la mémoire pour Y sur CPU
2) Allouer mémoire pour d_A, d_X et d_Y sur GPU
3) Le kernel 0 va initialiser la matrice d_A et d_X sur n threads
4) Le kernel 1 s'occupe du produit matriciel sur n threads
5) Le kernel 2 va effectuer un atomic_add sur la norme pour n threads afin que la norme soit disponible partout
6) Chaque thread calcule la racine carrée de la norme puis son inverse
7) Le kernel 3 calcule Y[i] sur n threads
8) Le kernel 4 effectue un atomic_add sur l'erreur pour n threads
9) Chaque thread calcule la racine carrée de l'erreur
10) Envoyer l'erreur du GPU à CPU


Paramètres pour améliorer la performance : 
	Nbre de threads par bloc
	Produit matrice vecteur par bloc => difficulté : la réduction (avec un atomic add ? perte de performance, voir  Shuffle Warp Reduce "https://devblogs.nvidia.com/faster-parallel-reductions-kepler/"
